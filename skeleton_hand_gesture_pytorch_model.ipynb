{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "skeleton_hand_gesture_pytorch_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranshurastogi29/skeleton_networks/blob/master/skeleton_hand_gesture_pytorch_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACry_vIswInt",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning for Hand Gesture Recognition with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIqcb9y4wInu",
        "colab_type": "text"
      },
      "source": [
        "This notebook is a demo pytorch implementation of the deep learning model for hand gesture recognition introduced in the article [Deep Learning for Hand Gesture Recognition on Skeletal Data](https://ieeexplore.ieee.org/document/8373818) from G. Devineau, F. Moutarde, W. Xi and J. Yang.\n",
        "\n",
        "\n",
        "For keras users, a simplified [keras version](https://colab.research.google.com/drive/1x_-jfJEaL6U5qFvLBUYa0yVQ_-FHI3P9#scrollTo=DsloIWyMA6EW) of the current colab is also available for convenience.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYwttYwrwInw",
        "colab_type": "text"
      },
      "source": [
        "### Overview of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF9j6w78wInx",
        "colab_type": "text"
      },
      "source": [
        "![Model Overview](https://raw.githubusercontent.com/guillaumephd/deep_learning_hand_gesture_recognition/master/images/pipeline.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIPpe_3nwIny",
        "colab_type": "text"
      },
      "source": [
        "### 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RLdxMOfwInz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "import sys\n",
        "if sys.version_info.major < 3:\n",
        "    print('You are using python 2, but you should rather use python 3.')\n",
        "    print('    If you still want to use python 2, ensure you import:')\n",
        "    print('    >> from __future__ import unicode_literals, print_function, division')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fmhkYESwIn3",
        "colab_type": "text"
      },
      "source": [
        "If you encounter an python error regarding a missing module at some point, uncomment the appropriate line in the cell below and run it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBDM1-XQwIn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment the following lines to install modules if needed:\n",
        "# -----------------------------------------------------------\n",
        "# --- required: numpy + sklearn + scipy:\n",
        "# !{sys.executable} -m pip install numpy scipy sklearn\n",
        "# --- required: torch\n",
        "# !{sys.executable} -m pip install torch  # <<------ advice: do not use this pip command and install torch via conda, with CUDA: see: https://pytorch.org/get-started/locally/\n",
        "# --- bonus: tensorboardX:\n",
        "# !{sys.executable} -m pip install tensorflow tensorflow-gpu\n",
        "# !{sys.executable} -m pip install tensorboardX\n",
        "# --- bonus: jupyter-lab:\n",
        "# !{sys.executable} -m pip install matplotlib ipython jupyter jupyter-lab pandas tqdm\n",
        "# !{sys.executable} -m pip install ipywidgets\n",
        "# !jupyter nbextension enable --py widgetsnbextension"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNuU8g0EwIn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import numpy\n",
        "import torch\n",
        "import pickle\n",
        "from scipy import ndimage as ndimage\n",
        "from sklearn.utils import shuffle\n",
        "import time\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkSFp85JwIn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (bonus) plot acc with tensorboard\n",
        "#   Command to start tensorboard if installed (requires tensorflow):\n",
        "#   $  tensorboard --logdir ./runs\n",
        "try:\n",
        "    from tensorboardX import SummaryWriter\n",
        "except:\n",
        "    # tensorboardX is not installed, just fail silently\n",
        "    class SummaryWriter():\n",
        "        def __init__(self):\n",
        "            pass\n",
        "        def add_scalar(self, tag, scalar_value, global_step=None, walltime=None):\n",
        "            pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4B0_tGawIoB",
        "colab_type": "code",
        "outputId": "f806a82d-fd2f-4886-eeac-16299ffec244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print('Using python {}.{}, with modules versions'.format(sys.version_info.major, sys.version_info.minor))\n",
        "print('-'*40)\n",
        "print('numpy == {}'.format(numpy.__version__))\n",
        "print('torch == {}'.format(torch.__version__))  # please use version 1.0 or above"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using python 3.6, with modules versions\n",
            "----------------------------------------\n",
            "numpy == 1.17.5\n",
            "torch == 1.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sABHssjwIoF",
        "colab_type": "text"
      },
      "source": [
        "### 2. Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmRygG0QwIoG",
        "colab_type": "text"
      },
      "source": [
        "We define some functions we'll need later on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWMTV22kwIoH",
        "colab_type": "text"
      },
      "source": [
        "#### 2.1. Gesture Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg1VDVGywIoI",
        "colab_type": "text"
      },
      "source": [
        "##### Option 1: Use your own custom Dataset\n",
        "To train the model on your own custom hand gesture dataset, edit the cells below. You'll need to adapt `load_data()`, `shuffle_dataset()`, `preprocess_data()` and `convert_to_pytorch_tensors()` according to your needs.\n",
        "\n",
        "The `load_data()` function should return the gesture tensors `x` and the labels `y`.\n",
        "\n",
        "The shape of the `x` tensor should be `(dataset_size, duration, n_channels)` where `n_channels = 3 * n_joints` for 3D pose data.\n",
        "\n",
        "---\n",
        "If your dataset does not fit into memory, you can use the straightforward pytorch Dataset class:\n",
        "\n",
        "    from torch.utils.data.dataset import Dataset\n",
        "    class MyCustomDataset(Dataset):\n",
        "\n",
        "        def __init__(self, root_dir):\n",
        "            self.sequences_names = ... # list sequences\n",
        "            self.root_dir = root_dir\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.sequences_names)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            if torch.is_tensor(idx):\n",
        "                idx = idx.tolist()\n",
        "\n",
        "            sample = ...load_somehow(self.sequences_names[idx]) # load sequence\n",
        "            return sample\n",
        "---\n",
        "\n",
        "##### Option 2: Use DHG14/28 or SHREC 17 Dataset\n",
        "\n",
        "If you don't have your own gesture dataset, you might want to download one of these hand gesture datasets:\n",
        "  - DHG 14/28 Dataset: http://www-rech.telecom-lille.fr/DHGdataset/\n",
        "  - SHREC 17 Track Dataset: http://www-rech.telecom-lille.fr/shrec2017-hand/)\n",
        "\n",
        "or here (ready-to-use dataset, pre-loaded into a single pickle file `shrec_data.pckl`):\n",
        "  - SHREC 17 Track Dataset: https://cloud.mines-paristech.fr/index.php/s/9U4bjHrvp8u2pnS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKkWThsg1n7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Option 1: Custom Dataset\n",
        "# ------------------------\n",
        "# On the left bar of this colaboratory notebook there is a section called \"Files\".\n",
        "# Upload your files there and use a path like \"/content/each_file_you_just_uploaded\" to load your data, e.g. in the load_data() function below"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAWvt0xqwh0d",
        "colab_type": "code",
        "outputId": "78cb6f2f-202b-4726-b4fe-b3d6f456520a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "# Option 2: Download the SHREC17 dataset \n",
        "# (either download the file manually or use the following wget command:)\n",
        "!wget https://cloud.mines-paristech.fr/index.php/s/9U4bjHrvp8u2pnS/download -O ./shrec_data.pckl"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-31 15:45:44--  https://cloud.mines-paristech.fr/index.php/s/9U4bjHrvp8u2pnS/download\n",
            "Resolving cloud.mines-paristech.fr (cloud.mines-paristech.fr)... 77.158.180.133\n",
            "Connecting to cloud.mines-paristech.fr (cloud.mines-paristech.fr)|77.158.180.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 253081919 (241M) [application/octet-stream]\n",
            "Saving to: ‘./shrec_data.pckl’\n",
            "\n",
            "./shrec_data.pckl   100%[===================>] 241.36M  6.56MB/s    in 30s     \n",
            "\n",
            "2020-01-31 15:46:15 (7.93 MB/s) - ‘./shrec_data.pckl’ saved [253081919/253081919]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDfbySnAwIoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(filepath='./shrec_data.pckl'):\n",
        "    \"\"\"\n",
        "    Returns hand gesture sequences (X) and their associated labels (Y).\n",
        "    Each sequence has two different labels.\n",
        "    The first label  Y describes the gesture class out of 14 possible gestures (e.g. swiping your hand to the right).\n",
        "    The second label Y describes the gesture class out of 28 possible gestures (e.g. swiping your hand to the right with your index pointed, or not pointed).\n",
        "    \"\"\"\n",
        "    file = open(filepath, 'rb')\n",
        "    data = pickle.load(file, encoding='latin1')  # <<---- change to 'latin1' to 'utf8' if the data does not load\n",
        "    file.close()\n",
        "    return data['x_train'], data['x_test'], data['y_train_14'], data['y_train_28'], data['y_test_14'], data['y_test_28']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYMAOcXYwIoL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_sequences_length(x_train, x_test, final_length=100):\n",
        "    \"\"\"\n",
        "    Resize the time series by interpolating them to the same length\n",
        "    \"\"\"\n",
        "    # please use python3. if you still use python2, important note: redefine the classic division operator / by importing it from the __future__ module\n",
        "    x_train = numpy.array([numpy.array([ndimage.zoom(x_i.T[j], final_length / len(x_i), mode='reflect') for j in range(numpy.size(x_i, 1))]).T for x_i in x_train])\n",
        "    x_test  = numpy.array([numpy.array([ndimage.zoom(x_i.T[j], final_length / len(x_i), mode='reflect') for j in range(numpy.size(x_i, 1)) ]).T for x_i in x_test])\n",
        "    return x_train, x_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQSIbT1LwIoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def shuffle_dataset(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28):\n",
        "    \"\"\"Shuffle the train/test data consistently.\"\"\"\n",
        "    # note: add random_state=0 for reproducibility\n",
        "    x_train, y_train_14, y_train_28 = shuffle(x_train, y_train_14, y_train_28)\n",
        "    x_test,  y_test_14,  y_test_28  = shuffle(x_test,  y_test_14,  y_test_28)\n",
        "    return x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwtgZ5E5wIoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28):\n",
        "    \"\"\"\n",
        "    Preprocess the data as you want: update as you want!\n",
        "        - possible improvement idea: make a PCA here\n",
        "    \"\"\"\n",
        "    x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = shuffle_dataset(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28)\n",
        "    x_train, x_test = resize_sequences_length(x_train, x_test, final_length=100)\n",
        "    return x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk71erCuwIoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_pytorch_tensors(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28):\n",
        "    # as numpy\n",
        "    y_train_14, y_train_28, y_test_14, y_test_28 = numpy.array(y_train_14), numpy.array(y_train_28), numpy.array(y_test_14), numpy.array(y_test_28)\n",
        "    \n",
        "    # -- REQUIRED by the pytorch loss function implementation --\n",
        "    # Remove 1 to all classes items (1-14 => 0-13 and 1-28 => 0-27)\n",
        "    y_train_14, y_train_28, y_test_14, y_test_28 = y_train_14 - 1, y_train_28 - 1, y_test_14 - 1, y_test_28 - 1\n",
        "    \n",
        "    # as torch\n",
        "    x_train, x_test = torch.from_numpy(x_train), torch.from_numpy(x_test)\n",
        "    y_train_14, y_train_28, y_test_14, y_test_28 = torch.from_numpy(y_train_14), torch.from_numpy(y_train_28), torch.from_numpy(y_test_14), torch.from_numpy(y_test_28)\n",
        "\n",
        "    # -- REQUIRED by the pytorch loss function implementation --\n",
        "    # correct the data type (for the loss function used)\n",
        "    x_train, x_test = x_train.type(torch.FloatTensor), x_test.type(torch.FloatTensor)\n",
        "    y_train_14, y_train_28, y_test_14, y_test_28 = y_train_14.type(torch.LongTensor), y_train_28.type(torch.LongTensor), y_test_14.type(torch.LongTensor), y_test_28.type(torch.LongTensor)\n",
        "    \n",
        "    return x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UpV2yNkwIoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------\n",
        "# Misc.\n",
        "# -------------\n",
        "def batch(tensor, batch_size=32):\n",
        "    \"\"\"Return a list of (mini) batches\"\"\"\n",
        "    tensor_list = []\n",
        "    length = tensor.shape[0]\n",
        "    i = 0\n",
        "    while True:\n",
        "        if (i + 1) * batch_size >= length:\n",
        "            tensor_list.append(tensor[i * batch_size: length])\n",
        "            return tensor_list\n",
        "        tensor_list.append(tensor[i * batch_size: (i + 1) * batch_size])\n",
        "        i += 1\n",
        "\n",
        "\n",
        "def time_since(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '{:02d}m {:02d}s'.format(int(m), int(s))\n",
        "\n",
        "\n",
        "def get_accuracy(model, x, y_ref):\n",
        "    \"\"\"Get the accuracy of the pytorch model on a batch\"\"\"\n",
        "    acc = 0.\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        predicted = model(x)\n",
        "        _, predicted = predicted.max(dim=1)\n",
        "        acc = 1.0 * (predicted == y_ref).sum().item() / y_ref.shape[0]\n",
        "\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlFxJwWAwIod",
        "colab_type": "text"
      },
      "source": [
        "### 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fMDI-QWwIoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HandGestureNet(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Summary\n",
        "    -------\n",
        "        Deep Learning Model for Hand Gesture classification using pose data only (no need for RGBD)\n",
        "        The model computes a succession of [convolutions and pooling] over time independently on each of the 66 (= 22 * 3) sequence channels.\n",
        "        Each of these computations are actually done at two different resolutions, that are later merged by concatenation\n",
        "        with the (pooled) original sequence channel.\n",
        "        Finally, a multi-layer perceptron merges all of the processed channels and outputs a classification.\n",
        "    \n",
        "    TL;DR:\n",
        "    ------\n",
        "        input ------------------------------------------------> split into n_channels channels [channel_i]\n",
        "            channel_i ----------------------------------------> 3x [conv/pool/dropout] low_resolution_i\n",
        "            channel_i ----------------------------------------> 3x [conv/pool/dropout] high_resolution_i\n",
        "            channel_i ----------------------------------------> pooled_i\n",
        "            low_resolution_i, high_resolution_i, pooled_i ----> output_channel_i\n",
        "        MLP(n_channels x [output_channel_i]) -------------------------> classification\n",
        "\n",
        "    Article / PDF:\n",
        "    --------------\n",
        "        https://ieeexplore.ieee.org/document/8373818\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, n_channels=66, n_classes=14, dropout_probability=0.2):\n",
        "\n",
        "        super(HandGestureNet, self).__init__()\n",
        "        \n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.dropout_probability = dropout_probability\n",
        "\n",
        "        # Layers ----------------------------------------------\n",
        "        self.all_conv_high = torch.nn.ModuleList([torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(in_channels=1, out_channels=8, kernel_size=7, padding=3),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AvgPool1d(2),\n",
        "\n",
        "            torch.nn.Conv1d(in_channels=8, out_channels=4, kernel_size=7, padding=3),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AvgPool1d(2),\n",
        "\n",
        "            torch.nn.Conv1d(in_channels=4, out_channels=4, kernel_size=7, padding=3),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(p=self.dropout_probability),\n",
        "            torch.nn.AvgPool1d(2)\n",
        "        ) for joint in range(n_channels)])\n",
        "\n",
        "        self.all_conv_low = torch.nn.ModuleList([torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(in_channels=1, out_channels=8, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AvgPool1d(2),\n",
        "\n",
        "            torch.nn.Conv1d(in_channels=8, out_channels=4, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AvgPool1d(2),\n",
        "\n",
        "            torch.nn.Conv1d(in_channels=4, out_channels=4, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(p=self.dropout_probability),\n",
        "            torch.nn.AvgPool1d(2)\n",
        "        ) for joint in range(n_channels)])\n",
        "\n",
        "        self.all_residual = torch.nn.ModuleList([torch.nn.Sequential(\n",
        "            torch.nn.AvgPool1d(2),\n",
        "            torch.nn.AvgPool1d(2),\n",
        "            torch.nn.AvgPool1d(2)\n",
        "        ) for joint in range(n_channels)])\n",
        "\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(in_features=9 * n_channels * 12, out_features=1936),  # <-- 12: depends of the sequences lengths (cf. below)\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(in_features=1936, out_features=n_classes)\n",
        "        )\n",
        "\n",
        "        # Initialization --------------------------------------\n",
        "        # Xavier init\n",
        "        for module in itertools.chain(self.all_conv_high, self.all_conv_low, self.all_residual):\n",
        "            for layer in module:\n",
        "                if layer.__class__.__name__ == \"Conv1d\":\n",
        "                    torch.nn.init.xavier_uniform_(layer.weight, gain=torch.nn.init.calculate_gain('relu'))\n",
        "                    torch.nn.init.constant_(layer.bias, 0.1)\n",
        "\n",
        "        for layer in self.fc:\n",
        "            if layer.__class__.__name__ == \"Linear\":\n",
        "                torch.nn.init.xavier_uniform_(layer.weight, gain=torch.nn.init.calculate_gain('relu'))\n",
        "                torch.nn.init.constant_(layer.bias, 0.1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        This function performs the actual computations of the network for a forward pass.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "            input: a tensor of gestures of shape (batch_size, duration, n_channels)\n",
        "                   (where n_channels = 3 * n_joints for 3D pose data)\n",
        "        \"\"\"\n",
        "\n",
        "        # Work on each channel separately\n",
        "        all_features = []\n",
        "\n",
        "        for channel in range(0, self.n_channels):\n",
        "            input_channel = input[:, :, channel]\n",
        "\n",
        "            # Add a dummy (spatial) dimension for the time convolutions\n",
        "            # Conv1D format : (batch_size, n_feature_maps, duration)\n",
        "            input_channel = input_channel.unsqueeze(1)\n",
        "\n",
        "            high = self.all_conv_high[channel](input_channel)\n",
        "            low = self.all_conv_low[channel](input_channel)\n",
        "            ap_residual = self.all_residual[channel](input_channel)\n",
        "\n",
        "            # Time convolutions are concatenated along the feature maps axis\n",
        "            output_channel = torch.cat([\n",
        "                high,\n",
        "                low,\n",
        "                ap_residual\n",
        "            ], dim=1)\n",
        "            all_features.append(output_channel)\n",
        "\n",
        "        # Concatenate along the feature maps axis\n",
        "        all_features = torch.cat(all_features, dim=1)\n",
        "        \n",
        "        # Flatten for the Linear layers\n",
        "        all_features = all_features.view(-1, 9 * self.n_channels * 12)  # <-- 12: depends of the initial sequence length (100).\n",
        "        # If you have shorter/longer sequences, you probably do NOT even need to modify the modify the network architecture:\n",
        "        # resampling your input gesture from T timesteps to 100 timesteps will (surprisingly) probably actually work as well!\n",
        "\n",
        "        # Fully-Connected Layers\n",
        "        output = self.fc(all_features)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiDdp4xrwIoi",
        "colab_type": "text"
      },
      "source": [
        "### 4. Data loading; Loss and Optimizer function; Neural Network Model creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNjzN2onwIoi",
        "colab_type": "text"
      },
      "source": [
        "If you use a custom dataset, you'll likely need to change the data loading part here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO08iDzWwIoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------\n",
        "# Data\n",
        "# -------------\n",
        "\n",
        "# Load the dataset\n",
        "x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = load_data()\n",
        "\n",
        "# Shuffle sequences and resize sequences\n",
        "x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = preprocess_data(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28)\n",
        "\n",
        "# Convert to pytorch variables\n",
        "x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28 = convert_to_pytorch_tensors(x_train, x_test, y_train_14, y_train_28, y_test_14, y_test_28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Od4PvSaNwIom",
        "colab_type": "text"
      },
      "source": [
        "If you use a custom dataset, you'll likely want to change `n_channels` and `n_classes` to match your values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf0rwXplwIon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------\n",
        "# Network instantiation\n",
        "# -------------\n",
        "model = HandGestureNet(n_channels=66, n_classes=14)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrzXfnl9wIor",
        "colab_type": "text"
      },
      "source": [
        "Reduce the learning rate to get smoother accuracy curves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkTjgTauwIos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -----------------------------------------------------\n",
        "# Loss function & Optimizer\n",
        "# -----------------------------------------------------\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BVrdOrcwIov",
        "colab_type": "text"
      },
      "source": [
        "### 5. Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLWgtKSQwIoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------------\n",
        "# Training\n",
        "# -------------\n",
        "\n",
        "\n",
        "def train(model, criterion, optimizer,\n",
        "          x_train, y_train, x_test, y_test,\n",
        "          force_cpu=False, num_epochs=5):\n",
        "    \n",
        "    # use a GPU (for speed) if you have one\n",
        "    device = torch.device(\"cuda\") if torch.cuda.is_available() and not force_cpu else torch.device(\"cpu\")\n",
        "    model = model.to(device)\n",
        "    x_train, y_train, x_test, y_test = x_train.to(device), y_train.to(device), x_test.to(device), y_test.to(device)\n",
        "    \n",
        "    # (bonus) log accuracy values to visualize them in tensorboard:\n",
        "    writer = SummaryWriter()\n",
        "    \n",
        "    # Prepare all mini-batches\n",
        "    x_train_batches = batch(x_train)\n",
        "    y_train_batches = batch(y_train)\n",
        "    \n",
        "    # Training starting time\n",
        "    start = time.time()\n",
        "\n",
        "    print('[INFO] Started to train the model.')\n",
        "    print('Training the model on {}.'.format('GPU' if device == torch.device('cuda') else 'CPU'))\n",
        "    \n",
        "    for ep in range(num_epochs):\n",
        "\n",
        "        # Ensure we're still in training mode\n",
        "        model.train()\n",
        "\n",
        "        current_loss = 0.0\n",
        "\n",
        "        for idx_batch, train_batches in enumerate(zip(x_train_batches, y_train_batches)):\n",
        "\n",
        "            # get a mini-batch of sequences\n",
        "            x_train_batch, y_train_batch = train_batches\n",
        "\n",
        "            # zero the gradient parameters\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            outputs = model(x_train_batch)\n",
        "\n",
        "            # backward + optimize\n",
        "            # backward\n",
        "            loss = criterion(outputs, y_train_batch)\n",
        "            loss.backward()\n",
        "            # optimize\n",
        "            optimizer.step()\n",
        "            # for an easy access\n",
        "            current_loss += loss.item()\n",
        "        \n",
        "        train_acc = get_accuracy(model, x_train, y_train)\n",
        "        test_acc = get_accuracy(model, x_test, y_test)\n",
        "        \n",
        "        writer.add_scalar('data/accuracy_train', train_acc, ep)\n",
        "        writer.add_scalar('data/accuracy_test', test_acc, ep)\n",
        "        print('Epoch #{:03d} | Time elapsed : {} | Loss : {:.4e} | Accuracy_train : {:.4e} | Accuracy_test : {:.4e}'.format(\n",
        "                ep + 1, time_since(start), current_loss, train_acc, test_acc))\n",
        "\n",
        "    print('[INFO] Finished training the model. Total time : {}.'.format(time_since(start)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YspFJiWZwIo2",
        "colab_type": "text"
      },
      "source": [
        "You can now train the model on your dataset!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDAO7GzA3dKq",
        "colab_type": "text"
      },
      "source": [
        "Note: You can use the GPUs provided by Google Colab to make the training faster: go to the “runtime” dropdown menu, select “change runtime type” and select GPU in the hardware accelerator drop-down menu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb4PTmmjwIo4",
        "colab_type": "code",
        "outputId": "0e857aa3-beac-4af5-8022-0ea5b773265e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "source": [
        "# Please adjust the training epochs count, and the other hyperparams (lr, dropout, ...), for a non-overfitted training according to your own needs.\n",
        "# tip: use tensorboard to display the accuracy (see cells above for tensorboard usage)\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "train(model=model, criterion=criterion, optimizer=optimizer,\n",
        "      x_train=x_train, y_train=y_train_14, x_test=x_test, y_test=y_test_14,\n",
        "      num_epochs=num_epochs)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Started to train the model.\n",
            "Training the model on GPU.\n",
            "Epoch #001 | Time elapsed : 00m 18s | Loss : 3.2757e+02 | Accuracy_train : 3.1633e-01 | Accuracy_test : 2.4851e-01\n",
            "Epoch #002 | Time elapsed : 00m 34s | Loss : 1.0756e+02 | Accuracy_train : 5.8163e-01 | Accuracy_test : 4.8268e-01\n",
            "Epoch #003 | Time elapsed : 00m 53s | Loss : 7.5192e+01 | Accuracy_train : 6.9847e-01 | Accuracy_test : 5.9737e-01\n",
            "Epoch #004 | Time elapsed : 01m 10s | Loss : 5.7016e+01 | Accuracy_train : 7.2908e-01 | Accuracy_test : 6.1171e-01\n",
            "Epoch #005 | Time elapsed : 01m 27s | Loss : 4.6112e+01 | Accuracy_train : 7.9388e-01 | Accuracy_test : 6.6547e-01\n",
            "Epoch #006 | Time elapsed : 01m 44s | Loss : 3.8300e+01 | Accuracy_train : 8.2704e-01 | Accuracy_test : 7.0131e-01\n",
            "Epoch #007 | Time elapsed : 02m 01s | Loss : 3.2308e+01 | Accuracy_train : 8.5357e-01 | Accuracy_test : 7.4671e-01\n",
            "Epoch #008 | Time elapsed : 02m 17s | Loss : 2.7940e+01 | Accuracy_train : 8.6990e-01 | Accuracy_test : 7.4910e-01\n",
            "Epoch #009 | Time elapsed : 02m 35s | Loss : 2.4550e+01 | Accuracy_train : 8.6378e-01 | Accuracy_test : 7.4313e-01\n",
            "Epoch #010 | Time elapsed : 02m 52s | Loss : 2.2800e+01 | Accuracy_train : 8.7143e-01 | Accuracy_test : 7.5508e-01\n",
            "Epoch #011 | Time elapsed : 03m 09s | Loss : 2.1166e+01 | Accuracy_train : 8.9694e-01 | Accuracy_test : 7.9689e-01\n",
            "Epoch #012 | Time elapsed : 03m 26s | Loss : 1.8657e+01 | Accuracy_train : 8.9592e-01 | Accuracy_test : 7.8614e-01\n",
            "Epoch #013 | Time elapsed : 03m 43s | Loss : 1.7735e+01 | Accuracy_train : 9.1122e-01 | Accuracy_test : 7.9092e-01\n",
            "Epoch #014 | Time elapsed : 04m 00s | Loss : 1.7256e+01 | Accuracy_train : 9.0765e-01 | Accuracy_test : 8.0406e-01\n",
            "Epoch #015 | Time elapsed : 04m 17s | Loss : 1.5469e+01 | Accuracy_train : 9.3469e-01 | Accuracy_test : 8.3871e-01\n",
            "Epoch #016 | Time elapsed : 04m 35s | Loss : 1.3162e+01 | Accuracy_train : 9.3010e-01 | Accuracy_test : 8.5066e-01\n",
            "Epoch #017 | Time elapsed : 04m 51s | Loss : 1.3226e+01 | Accuracy_train : 9.4592e-01 | Accuracy_test : 8.5902e-01\n",
            "Epoch #018 | Time elapsed : 05m 09s | Loss : 1.2305e+01 | Accuracy_train : 9.4235e-01 | Accuracy_test : 8.4827e-01\n",
            "Epoch #019 | Time elapsed : 05m 26s | Loss : 1.2159e+01 | Accuracy_train : 9.2551e-01 | Accuracy_test : 8.3035e-01\n",
            "Epoch #020 | Time elapsed : 05m 43s | Loss : 1.1715e+01 | Accuracy_train : 9.2347e-01 | Accuracy_test : 8.2557e-01\n",
            "[INFO] Finished training the model. Total time : 05m 43s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiC4nQ23wIo7",
        "colab_type": "text"
      },
      "source": [
        "### 6. (When you're happy with the training:) Save the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AJfKUyZwIo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'gesture_pretrained_model.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlxFW_9hwIpA",
        "colab_type": "text"
      },
      "source": [
        "### 7. Get a trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcj_-dvBUXVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reminder: first redefine/load the HandGestureNet class before you use it, if you want to use it elsewhere\n",
        "model = HandGestureNet(n_channels=66, n_classes=14)\n",
        "model.load_state_dict(torch.load('gesture_pretrained_model.pt'))\n",
        "model.eval()\n",
        "\n",
        "# make predictions\n",
        "with torch.no_grad():\n",
        "    demo_gesture_batch = torch.randn(32, 100, 66)\n",
        "    predictions = model(demo_gesture_batch)\n",
        "    _, predictions = predictions.max(dim=1)\n",
        "    print(\"Predicted gesture classes: {}\".format(predictions.tolist()))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}